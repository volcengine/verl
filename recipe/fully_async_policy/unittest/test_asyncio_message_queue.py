# Copyright 2025 Meituan Ltd. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# æµ‹è¯•ä½¿ç”¨ asyncio çš„ MessageQueue
# å¯¹æ¯” @ray.remote(num_cpus, max_concurrency) å‚æ•°çš„å®é™…æ•ˆæœ

import asyncio
import random

# å¯¼å…¥ä¿®æ”¹åçš„ MessageQueue
import time
from dataclasses import dataclass

import ray
from omegaconf import DictConfig

from recipe.fully_async_policy.message_queue import MessageQueue, MessageQueueClient, QueueSample


@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""

    async_training: dict


def create_test_config() -> DictConfig:
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    from omegaconf import OmegaConf

    config_dict = {"async_training": {"staleness_threshold": 3}}
    return OmegaConf.create(config_dict)


class AsyncMessageQueueTester:
    """å¼‚æ­¥æ¶ˆæ¯é˜Ÿåˆ—æµ‹è¯•å™¨"""

    def __init__(self):
        self.config = create_test_config()

    async def test_basic_async_operations(self):
        """æµ‹è¯•åŸºæœ¬å¼‚æ­¥æ“ä½œ"""
        print("\nğŸ§ª æµ‹è¯•åŸºæœ¬å¼‚æ­¥æ“ä½œ")
        print("=" * 50)

        # åˆ›å»ºMessageQueue Actor
        queue_actor = MessageQueue.remote(self.config, max_queue_size=100)
        client = MessageQueueClient(queue_actor)

        # æµ‹è¯•å¼‚æ­¥æ”¾å…¥æ ·æœ¬
        test_samples = [
            QueueSample(
                data={"task_id": f"task_{i}", "content": f"æµ‹è¯•æ•°æ®_{i}"},
                rollout_metadata={"timestamp": time.time(), "version": 1},
            )
            for i in range(10)
        ]

        # å¼‚æ­¥å¹¶å‘æ”¾å…¥æ ·æœ¬
        put_tasks = []
        for i, sample in enumerate(test_samples):
            task = asyncio.create_task(client.put_sample(sample, param_version=1), name=f"put_task_{i}")
            put_tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰æ”¾å…¥ä»»åŠ¡å®Œæˆ
        put_results = await asyncio.gather(*put_tasks)
        successful_puts = sum(put_results)

        print(f"âœ… æˆåŠŸæ”¾å…¥ {successful_puts}/{len(test_samples)} ä¸ªæ ·æœ¬")

        # å¼‚æ­¥è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await client.get_statistics()
        print(f"ğŸ“Š é˜Ÿåˆ—ç»Ÿè®¡: {stats}")

        # å¼‚æ­¥è·å–æ ·æœ¬
        samples_batch, queue_size = await client.get_samples(min_batch_count=5)
        print(f"ğŸ“¦ è·å–äº† {len(samples_batch)} ä¸ªæ ·æœ¬ï¼Œå‰©ä½™é˜Ÿåˆ—å¤§å°: {queue_size}")

        # æ¸…ç†
        await client.shutdown()

        return successful_puts

    async def test_concurrent_producers_consumers(self):
        """æµ‹è¯•å¹¶å‘ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…"""
        print("\nğŸ­ æµ‹è¯•å¹¶å‘ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…")
        print("=" * 50)

        # åˆ›å»º MessageQueue Actor
        queue_actor = MessageQueue.remote(self.config, max_queue_size=200)
        client = MessageQueueClient(queue_actor)

        # ç”Ÿäº§è€…åç¨‹
        async def producer(producer_id: int, sample_count: int):
            """ç”Ÿäº§è€…åç¨‹"""
            produced = 0
            for i in range(sample_count):
                sample = QueueSample(
                    data={
                        "producer_id": producer_id,
                        "task_id": f"producer_{producer_id}_task_{i}",
                        "content": f"æ¥è‡ªç”Ÿäº§è€…{producer_id}çš„æ•°æ®{i}",
                    },
                    rollout_metadata={"producer_timestamp": time.time(), "producer_id": producer_id},
                )

                success = await client.put_sample(sample, param_version=1)
                if success:
                    produced += 1

                # æ¨¡æ‹Ÿç”Ÿäº§é—´éš”
                await asyncio.sleep(random.uniform(0.01, 0.1))

            print(f"ğŸ­ ç”Ÿäº§è€…{producer_id} å®Œæˆï¼ŒæˆåŠŸç”Ÿäº§ {produced} ä¸ªæ ·æœ¬")
            return produced

        # æ¶ˆè´¹è€…åç¨‹
        async def consumer(consumer_id: int, target_count: int):
            """æ¶ˆè´¹è€…åç¨‹"""
            consumed = 0
            start_time = time.time()

            while consumed < target_count:
                try:
                    # å°è¯•è·å–æ ·æœ¬ï¼Œè®¾ç½®è¶…æ—¶
                    sample = await asyncio.wait_for(client.get_sample(), timeout=2.0)

                    if sample is not None:
                        consumed += 1

                        if consumed % 10 == 0:
                            print(f"ğŸ½ï¸  æ¶ˆè´¹è€…{consumer_id} å·²æ¶ˆè´¹ {consumed} ä¸ªæ ·æœ¬")
                    else:
                        print(f"âš ï¸ æ¶ˆè´¹è€…{consumer_id} æ”¶åˆ°ç©ºæ ·æœ¬ï¼Œé˜Ÿåˆ—å¯èƒ½å·²å…³é—­")
                        break

                except asyncio.TimeoutError:
                    print(f"â° æ¶ˆè´¹è€…{consumer_id} è¶…æ—¶ï¼Œæ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€...")
                    stats = await client.get_statistics()
                    if stats["queue_size"] == 0:
                        print(f"ğŸ“­ é˜Ÿåˆ—ä¸ºç©ºï¼Œæ¶ˆè´¹è€…{consumer_id} ç­‰å¾…...")
                        await asyncio.sleep(0.5)
                    continue

                # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                await asyncio.sleep(random.uniform(0.02, 0.05))

            elapsed = time.time() - start_time
            print(f"ğŸ½ï¸  æ¶ˆè´¹è€…{consumer_id} å®Œæˆï¼Œæ¶ˆè´¹äº† {consumed} ä¸ªæ ·æœ¬ï¼Œè€—æ—¶ {elapsed:.2f}s")
            return consumed

        # å¯åŠ¨å¹¶å‘ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…
        num_producers = 3
        num_consumers = 2
        samples_per_producer = 20

        # åˆ›å»ºç”Ÿäº§è€…ä»»åŠ¡
        producer_tasks = [
            asyncio.create_task(producer(i, samples_per_producer), name=f"producer_{i}") for i in range(num_producers)
        ]

        # åˆ›å»ºæ¶ˆè´¹è€…ä»»åŠ¡
        total_expected_samples = num_producers * samples_per_producer
        samples_per_consumer = total_expected_samples // num_consumers

        consumer_tasks = [
            asyncio.create_task(
                consumer(i, samples_per_consumer + (5 if i == 0 else 0)),  # ç¬¬ä¸€ä¸ªæ¶ˆè´¹è€…å¤šå¤„ç†ä¸€äº›
                name=f"consumer_{i}",
            )
            for i in range(num_consumers)
        ]

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        start_time = time.time()

        producer_results = await asyncio.gather(*producer_tasks, return_exceptions=True)
        consumer_results = await asyncio.gather(*consumer_tasks, return_exceptions=True)

        end_time = time.time()

        # ç»Ÿè®¡ç»“æœ
        total_produced = sum(r for r in producer_results if isinstance(r, int))
        total_consumed = sum(r for r in consumer_results if isinstance(r, int))

        print("\nğŸ“ˆ å¹¶å‘æµ‹è¯•ç»“æœ:")
        print(f"   æ€»ç”Ÿäº§æ ·æœ¬: {total_produced}")
        print(f"   æ€»æ¶ˆè´¹æ ·æœ¬: {total_consumed}")
        print(f"   æ€»è€—æ—¶: {end_time - start_time:.2f}s")
        print(f"   ç”Ÿäº§æ•ˆç‡: {total_produced / (end_time - start_time):.2f} samples/s")
        print(f"   æ¶ˆè´¹æ•ˆç‡: {total_consumed / (end_time - start_time):.2f} samples/s")

        # æœ€ç»ˆç»Ÿè®¡
        final_stats = await client.get_statistics()
        print(f"ğŸ“Š æœ€ç»ˆé˜Ÿåˆ—ç»Ÿè®¡: {final_stats}")

        # æ¸…ç†
        await client.shutdown()

        return total_produced, total_consumed

    async def compare_resource_configurations(self):
        """å¯¹æ¯”ä¸åŒèµ„æºé…ç½®çš„æ•ˆæœ"""
        print("\nâš¡ å¯¹æ¯”ä¸åŒèµ„æºé…ç½®çš„æ•ˆæœ")
        print("=" * 50)

        # æµ‹è¯•é…ç½®åˆ—è¡¨
        configs = [
            {"name": "é»˜è®¤é…ç½®", "num_cpus": None, "max_concurrency": None, "decorator": ray.remote},
            {
                "name": "é«˜CPUä½å¹¶å‘",
                "num_cpus": 4,
                "max_concurrency": 5,
                "decorator": lambda: ray.remote(num_cpus=4, max_concurrency=5),
            },
            {
                "name": "ä½CPUé«˜å¹¶å‘",
                "num_cpus": 1,
                "max_concurrency": 20,
                "decorator": lambda: ray.remote(num_cpus=1, max_concurrency=20),
            },
            {
                "name": "å¹³è¡¡é…ç½®",
                "num_cpus": 2,
                "max_concurrency": 10,
                "decorator": lambda: ray.remote(num_cpus=2, max_concurrency=10),
            },
        ]

        results = {}

        for config in configs:
            print(f"\nğŸ§ª æµ‹è¯•é…ç½®: {config['name']}")
            print(f"   num_cpus: {config['num_cpus']}")
            print(f"   max_concurrency: {config['max_concurrency']}")

            # åŠ¨æ€åˆ›å»ºMessageQueueç±»
            if config["num_cpus"] is None:
                QueueClass = MessageQueue
            else:
                QueueClass = config["decorator"]()(MessageQueue)

            # åˆ›å»ºqueueå®ä¾‹
            queue_actor = QueueClass.remote(self.config, max_queue_size=100)
            client = MessageQueueClient(queue_actor)

            # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
            start_time = time.time()

            # å¹¶å‘æ”¾å…¥å¤§é‡æ ·æœ¬
            sample_count = 50
            put_tasks = []

            for i in range(sample_count):
                sample = QueueSample(
                    data={
                        "task_id": f"perf_test_{i}",
                        "config": config["name"],
                        "data_size": random.randint(100, 1000),
                    },
                    rollout_metadata={"config_test": True},
                )

                task = asyncio.create_task(client.put_sample(sample, param_version=1))
                put_tasks.append(task)

                # æ¨¡æ‹Ÿæµå¼åˆ°è¾¾
                if i % 10 == 0:
                    await asyncio.sleep(0.01)

            # ç­‰å¾…æ‰€æœ‰putå®Œæˆ
            put_results = await asyncio.gather(*put_tasks)
            put_time = time.time() - start_time

            # è·å–æ‰€æœ‰æ ·æœ¬
            get_start_time = time.time()
            all_samples = []

            while True:
                samples_batch, queue_size = await client.get_samples(min_batch_count=1)
                if not samples_batch:
                    break
                all_samples.extend(samples_batch)

                if queue_size == 0:
                    break

            get_time = time.time() - get_start_time
            total_time = time.time() - start_time

            successful_puts = sum(put_results)

            # è®°å½•ç»“æœ
            results[config["name"]] = {
                "successful_puts": successful_puts,
                "retrieved_samples": len(all_samples),
                "put_time": put_time,
                "get_time": get_time,
                "total_time": total_time,
                "put_throughput": successful_puts / put_time if put_time > 0 else 0,
                "get_throughput": len(all_samples) / get_time if get_time > 0 else 0,
                "total_throughput": (successful_puts + len(all_samples)) / total_time if total_time > 0 else 0,
            }

            print(f"   âœ… æ”¾å…¥: {successful_puts}/{sample_count}")
            print(f"   ğŸ“¦ è·å–: {len(all_samples)}")
            print(f"   â±ï¸  æ”¾å…¥è€—æ—¶: {put_time:.3f}s")
            print(f"   â±ï¸  è·å–è€—æ—¶: {get_time:.3f}s")
            print(f"   ğŸš€ æ”¾å…¥ååé‡: {successful_puts / put_time:.2f} ops/s")

            # æ¸…ç†
            await client.shutdown()

            # é—´éš”
            await asyncio.sleep(1)

        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        print("\nğŸ“Š èµ„æºé…ç½®å¯¹æ¯”æŠ¥å‘Š")
        print("=" * 80)
        print(f"{'é…ç½®åç§°':<15} {'æ”¾å…¥ååé‡':<12} {'è·å–ååé‡':<12} {'æ€»ååé‡':<12} {'æ€»è€—æ—¶':<10}")
        print("-" * 80)

        best_config = ""
        best_throughput = 0

        for config_name, result in results.items():
            put_throughput = result["put_throughput"]
            get_throughput = result["get_throughput"]
            total_throughput = result["total_throughput"]
            total_time = result["total_time"]

            print(
                f"{config_name:<15} {put_throughput:<12.2f} {get_throughput:<12.2f} "
                f"{total_throughput:<12.2f} {total_time:<10.3f}s"
            )

            if total_throughput > best_throughput:
                best_throughput = total_throughput
                best_config = config_name

        print(f"\nğŸ† æœ€ä½³é…ç½®: {best_config} (æ€»ååé‡: {best_throughput:.2f} ops/s)")

        return results


async def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–Ray
    if not ray.is_initialized():
        ray.init(
            num_cpus=8,
            object_store_memory=1000000000,  # 1GB
            ignore_reinit_error=True,
        )

    print("ğŸ¯ å¼‚æ­¥MessageQueueæµ‹è¯•")
    print(f"Rayé›†ç¾¤èµ„æº: {ray.cluster_resources()}")

    tester = AsyncMessageQueueTester()

    try:
        # åŸºæœ¬å¼‚æ­¥æ“ä½œæµ‹è¯•
        await tester.test_basic_async_operations()

        # å¹¶å‘ç”Ÿäº§è€…æ¶ˆè´¹è€…æµ‹è¯•
        await tester.test_concurrent_producers_consumers()

        # èµ„æºé…ç½®å¯¹æ¯”æµ‹è¯•
        await tester.compare_resource_configurations()

        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")

        # æ€»ç»“
        print("\nğŸ“‹ æ€»ç»“:")
        print("1. ä½¿ç”¨ asyncio åçš„ä¼˜åŠ¿:")
        print("   - çœŸæ­£çš„å¼‚æ­¥ç­‰å¾…ï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯")
        print("   - æ›´å¥½çš„å¹¶å‘æ€§èƒ½")
        print("   - ä¸Rayçš„å¼‚æ­¥æ¥å£å®Œç¾é›†æˆ")

        print("\n2. èµ„æºé…ç½®å»ºè®®:")
        print("   - num_cpus: æ§åˆ¶CPUèµ„æºåˆ†é…ï¼Œå½±å“è®¡ç®—å¯†é›†å‹ä»»åŠ¡")
        print("   - max_concurrency: æ§åˆ¶å¹¶å‘æ•°ï¼Œå½±å“I/Oå¯†é›†å‹ä»»åŠ¡")
        print("   - å¯¹äºMessageQueue: æ¨è num_cpus=2, max_concurrency=20")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

    finally:
        ray.shutdown()


if __name__ == "__main__":
    asyncio.run(main())
