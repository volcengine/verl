{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58736775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/veRL/veRL/cyk/vla-mix/verl\")\n",
    "sys.path.append(\"/file_system/cyk/vla_mix/LIBERO/\")\n",
    "import functools\n",
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "original_torch_load = torch.load\n",
    "\n",
    "\n",
    "# @functools.wraps(original_torch_load)\n",
    "# def new_torch_load(*args, **kwargs):\n",
    "#     if \"weights_only\" not in kwargs:\n",
    "#         kwargs[\"weights_only\"] = False\n",
    "#     return original_torch_load(*args, **kwargs)\n",
    "\n",
    "\n",
    "# torch.load = new_torch_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45b7b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LIBERO constants:\n",
      "  NUM_ACTIONS_CHUNK = 8\n",
      "  ACTION_DIM = 7\n",
      "  PROPRIO_DIM = 8\n",
      "  ACTION_PROPRIO_NORMALIZATION_TYPE = NormalizationType.BOUNDS_Q99\n",
      "If needed, manually set the correct constants in `prismatic/vla/constants.py`!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from verl.models.openvla_oft.configuration_prismatic import OpenVLAConfig\n",
    "from verl.models.openvla_oft.modeling_prismatic import OpenVLAForActionPrediction\n",
    "from verl.models.openvla_oft.processing_prismatic import PrismaticImageProcessor, PrismaticProcessor\n",
    "# from transformers import AutoConfig, AutoImageProcessor, AutoModelForVision2Seq, AutoProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772c1c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "PrismaticForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "OpenVLAForActionPrediction has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "WARNING:2025-10-13 12:26:06,895:Expected `transformers==4.40.1` and `tokenizers==0.19.1` but got `transformers==4.53.2` and `tokenizers==0.21.4`; there might be inference-time regressions due to dependency changes. If in doubt, pleaseuse the above versions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961f086fc51a42d7846ef66d00a692c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PrismaticForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "OpenVLAForActionPrediction has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "PrismaticForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "OpenVLAForActionPrediction has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenVLAForActionPrediction(\n",
       "  (vision_backbone): PrismaticVisionBackbone(\n",
       "    (featurizer): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): LayerScale()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): LayerScale()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "    (fused_featurizer): VisionTransformer(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))\n",
       "        (norm): Identity()\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (patch_drop): Identity()\n",
       "      (norm_pre): Identity()\n",
       "      (blocks): Sequential(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (12): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (13): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (14): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (15): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (16): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (17): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (18): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (19): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (20): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (21): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (22): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (23): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (24): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (25): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "        (26): Block(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (q_norm): Identity()\n",
       "            (k_norm): Identity()\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls1): Identity()\n",
       "          (drop_path1): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (ls2): Identity()\n",
       "          (drop_path2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn_pool): AttentionPoolLatent(\n",
       "        (q): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        (kv): Linear(in_features=1152, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (fc_norm): Identity()\n",
       "      (head_drop): Dropout(p=0.0, inplace=False)\n",
       "      (head): Identity()\n",
       "    )\n",
       "  )\n",
       "  (projector): PrismaticProjector(\n",
       "    (fc1): Linear(in_features=2176, out_features=8704, bias=True)\n",
       "    (fc2): Linear(in_features=8704, out_features=4096, bias=True)\n",
       "    (fc3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (act_fn1): GELU(approximate='none')\n",
       "    (act_fn2): GELU(approximate='none')\n",
       "  )\n",
       "  (language_model): LlamaForCausalLM(\n",
       "    (model): LlamaModel(\n",
       "      (embed_tokens): Embedding(32064, 4096, padding_idx=32000)\n",
       "      (layers): ModuleList(\n",
       "        (0-31): 32 x LlamaDecoderLayer(\n",
       "          (self_attn): LlamaAttention(\n",
       "            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          )\n",
       "          (mlp): LlamaMLP(\n",
       "            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "          (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): LlamaRMSNorm((4096,), eps=1e-06)\n",
       "      (rotary_emb): LlamaRotaryEmbedding()\n",
       "    )\n",
       "    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path = \"/file_system/common-models/Haozhan72-kangsheng/Openvla-oft-SFT-libero10-trajall/\"\n",
    "INFER_DEVICE = \"cuda:0\"\n",
    "processor = PrismaticProcessor.from_pretrained(local_path, trust_remote_code=True)\n",
    "tokenizer=processor.tokenizer\n",
    "\n",
    "# override model kwargs\n",
    "actor_model_config = OpenVLAConfig.from_pretrained(local_path, trust_remote_code=True)\n",
    "\n",
    "torch_dtype = torch.float32\n",
    "actor_module = OpenVLAForActionPrediction.from_pretrained(\n",
    "                                        pretrained_model_name_or_path=local_path,\n",
    "                                        torch_dtype=torch_dtype,\n",
    "                                        #attn_implementation=\"flash_attention_2\",\n",
    "                                        config=actor_model_config,              \n",
    "                                        trust_remote_code=True,\n",
    "                                    )\n",
    "actor_module.vision_backbone.set_num_images_in_input(1)\n",
    "dataset_statistics_path = os.path.join(local_path, \"dataset_statistics.json\")\n",
    "if os.path.isfile(dataset_statistics_path):\n",
    "    with open(dataset_statistics_path, \"r\") as f:\n",
    "        norm_stats = json.load(f)\n",
    "    actor_module.norm_stats = norm_stats\n",
    "actor_module = actor_module.to(INFER_DEVICE)\n",
    "actor_module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa27be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def center_crop_image(image: Image.Image) -> Image.Image:\n",
    "\n",
    "    crop_scale = 0.9\n",
    "    orig_w, orig_h = image.size\n",
    "    image_tensor = F.to_tensor(image)\n",
    "    crop_h = int(orig_h * crop_scale)\n",
    "    crop_w = int(orig_w * crop_scale)\n",
    "    image_tensor = F.center_crop(image_tensor, (crop_h, crop_w))\n",
    "    image_tensor = F.resize(image_tensor, (orig_h, orig_w))\n",
    "    final_image = F.to_pil_image(image_tensor)\n",
    "    \n",
    "    final_image = final_image.convert(\"RGB\")\n",
    "    return final_image\n",
    "\n",
    "# def process_input(inputs:list, task_descriptions:list, config):\n",
    "    \n",
    "#     batchdata = {\"input_ids\":[],\"attention_mask\":[],\"pixel_values\":[]}  \n",
    "    \n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i]\n",
    "#         task_description = task_descriptions[i]\n",
    "        \n",
    "#         image = Image.fromarray(input[\"full_image\"]).convert(\"RGB\")\n",
    "#         if config[\"center_crop\"]:\n",
    "#             image = center_crop_image(image)\n",
    "#         prompt = f\"In: What action should the robot take to {task_description.lower()}?\\nOut:\"\n",
    "#         batch_feature  = processor(prompt, image)\n",
    "        \n",
    "#         if \"wrist_image\" in input.keys():\n",
    "#             wrist_image = Image.fromarray(input[\"wrist_image\"]).convert(\"RGB\")\n",
    "#             if config[\"center_crop\"]:\n",
    "#                 wrist_image = center_crop_image(wrist_image)\n",
    "#             wrist_batch_feature = processor(prompt, wrist_image)\n",
    "#             primary_pixel_values = batch_feature[\"pixel_values\"]\n",
    "#             batch_feature[\"pixel_values\"] = torch.cat([primary_pixel_values] + [wrist_batch_feature[\"pixel_values\"]], dim=1)\n",
    "            \n",
    "#         input_ids = batch_feature[\"input_ids\"]\n",
    "#         attention_mask = batch_feature[\"attention_mask\"]\n",
    "#         pixel_values = batch_feature[\"pixel_values\"]\n",
    "        \n",
    "#         if not torch.all(input_ids[:, -1] == 29871):\n",
    "#             input_ids = torch.cat(\n",
    "#                 (input_ids, torch.unsqueeze(torch.Tensor([29871]).long(), dim=0).to(input_ids.device)), dim=1\n",
    "#             )\n",
    "#             attention_mask = torch.cat(\n",
    "#                 (attention_mask, torch.unsqueeze(torch.Tensor([True]).bool(), dim=0).to(attention_mask.device)), dim=1\n",
    "#             )\n",
    "        \n",
    "#         batchdata[\"input_ids\"].append(input_ids)    \n",
    "#         batchdata[\"attention_mask\"].append(attention_mask)    \n",
    "#         batchdata[\"pixel_values\"].append(pixel_values)    \n",
    "    \n",
    "    \n",
    "#     device = torch.device('cuda') \n",
    "    \n",
    "#     batchdata[\"input_ids\"] = [x.transpose(0, 1) for x in batchdata[\"input_ids\"]]\n",
    "#     batchdata[\"attention_mask\"] = [x.transpose(0, 1) for x in batchdata[\"attention_mask\"]]\n",
    "#     batchdata[\"input_ids\"] = pad_sequence(batchdata[\"input_ids\"], batch_first=True, padding_value=processor.tokenizer.pad_token_id).squeeze(-1).to(device)\n",
    "#     batchdata[\"attention_mask\"] = pad_sequence(batchdata[\"attention_mask\"], batch_first=True, padding_value=0).squeeze(-1).to(device)\n",
    "    \n",
    "#     padding_mask = batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id)\n",
    "#     assert  torch.all(padding_mask==batchdata[\"attention_mask\"].ne(0))\n",
    "#     padding_mask = ~padding_mask\n",
    "#     padding_mask = padding_mask.int() \n",
    "#     sorted_indices = torch.argsort(padding_mask, dim=1, descending=True, stable=True)\n",
    "#     batchdata[\"input_ids\"] = torch.gather(batchdata[\"input_ids\"], 1, sorted_indices)\n",
    "#     batchdata[\"attention_mask\"] = torch.gather(batchdata[\"attention_mask\"], 1, sorted_indices)\n",
    "    \n",
    "    \n",
    "#     batchdata[\"pixel_values\"] = torch.cat(batchdata[\"pixel_values\"] , dim=0).to(device)\n",
    "#     assert torch.all(batchdata[\"attention_mask\"].ne(0) == batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id))\n",
    "\n",
    "#     return batchdata\n",
    "def process_input(venv_obs, config):\n",
    "    \n",
    "    batchdata = {\"input_ids\":[],\"attention_mask\":[],\"pixel_values\":[]}  \n",
    "    \n",
    "    task_descriptions = venv_obs[\"task_descriptions\"]\n",
    "    images_and_states = venv_obs[\"images_and_states\"]\n",
    "    for i in range(len(venv_obs[\"task_descriptions\"])):\n",
    "        task_description = task_descriptions[i]\n",
    "        \n",
    "        image = Image.fromarray(images_and_states[\"full_image\"][i].numpy()).convert(\"RGB\")\n",
    "        if config[\"center_crop\"]:\n",
    "            image = center_crop_image(image)\n",
    "        prompt = f\"In: What action should the robot take to {task_description.lower()}?\\nOut:\"\n",
    "        batch_feature  = processor(prompt, image)\n",
    "        \n",
    "        # if \"wrist_image\" in venv_obs.keys():\n",
    "        #     wrist_image = Image.fromarray(input[\"wrist_image\"]).convert(\"RGB\")\n",
    "        #     if config[\"center_crop\"]:\n",
    "        #         wrist_image = center_crop_image(wrist_image)\n",
    "        #     wrist_batch_feature = processor(prompt, wrist_image)\n",
    "        #     primary_pixel_values = batch_feature[\"pixel_values\"]\n",
    "        #     batch_feature[\"pixel_values\"] = torch.cat([primary_pixel_values] + [wrist_batch_feature[\"pixel_values\"]], dim=1)\n",
    "            \n",
    "        input_ids = batch_feature[\"input_ids\"]\n",
    "        attention_mask = batch_feature[\"attention_mask\"]\n",
    "        pixel_values = batch_feature[\"pixel_values\"]\n",
    "        \n",
    "        if not torch.all(input_ids[:, -1] == 29871):\n",
    "            input_ids = torch.cat(\n",
    "                (input_ids, torch.unsqueeze(torch.Tensor([29871]).long(), dim=0).to(input_ids.device)), dim=1\n",
    "            )\n",
    "            attention_mask = torch.cat(\n",
    "                (attention_mask, torch.unsqueeze(torch.Tensor([True]).bool(), dim=0).to(attention_mask.device)), dim=1\n",
    "            )\n",
    "        \n",
    "        batchdata[\"input_ids\"].append(input_ids)    \n",
    "        batchdata[\"attention_mask\"].append(attention_mask)    \n",
    "        batchdata[\"pixel_values\"].append(pixel_values)    \n",
    "    \n",
    "    \n",
    "    device = torch.device('cuda') \n",
    "    \n",
    "    batchdata[\"input_ids\"] = [x.transpose(0, 1) for x in batchdata[\"input_ids\"]]\n",
    "    batchdata[\"attention_mask\"] = [x.transpose(0, 1) for x in batchdata[\"attention_mask\"]]\n",
    "    batchdata[\"input_ids\"] = pad_sequence(batchdata[\"input_ids\"], batch_first=True, padding_value=processor.tokenizer.pad_token_id).squeeze(-1).to(device)\n",
    "    batchdata[\"attention_mask\"] = pad_sequence(batchdata[\"attention_mask\"], batch_first=True, padding_value=0).squeeze(-1).to(device)\n",
    "    \n",
    "    padding_mask = batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id)\n",
    "    assert  torch.all(padding_mask==batchdata[\"attention_mask\"].ne(0))\n",
    "    padding_mask = ~padding_mask\n",
    "    padding_mask = padding_mask.int() \n",
    "    sorted_indices = torch.argsort(padding_mask, dim=1, descending=True, stable=True)\n",
    "    batchdata[\"input_ids\"] = torch.gather(batchdata[\"input_ids\"], 1, sorted_indices)\n",
    "    batchdata[\"attention_mask\"] = torch.gather(batchdata[\"attention_mask\"], 1, sorted_indices)\n",
    "    \n",
    "    \n",
    "    batchdata[\"pixel_values\"] = torch.cat(batchdata[\"pixel_values\"] , dim=0).to(device)\n",
    "    assert torch.all(batchdata[\"attention_mask\"].ne(0) == batchdata[\"input_ids\"].ne(processor.tokenizer.pad_token_id))\n",
    "\n",
    "    return batchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef87aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO_SAMPLE = True\n",
    "DO_SAMPLE = False\n",
    "TEMP = 1.6\n",
    "# TEMP = 0.2\n",
    "UNNORM_KEY = \"libero_10\"\n",
    "UNNORM_KEY = f\"{UNNORM_KEY}_no_noops\"\n",
    "MAX_PROMPT_LENGTH = 512\n",
    "def pad_sequence_to_length(tensors, max_seq_len, pad_token_id, left_pad=False):\n",
    "    \"\"\"\n",
    "    pad a 2D tensors (e.g. responses, logprobs) in the last dim to max_seq_length.\n",
    "    input shape: [bs, seq_length]\n",
    "    output shape: [bs, max_seq_length]\n",
    "    (0, max_seq_len - tensors.shape[-1]) means right pad to max_seq_length and no left pad\n",
    "    \"\"\"\n",
    "    if tensors.shape[-1] >= max_seq_len:\n",
    "        return tensors\n",
    "    pad_tuple = (max_seq_len - tensors.shape[-1], 0) if left_pad else (0, max_seq_len - tensors.shape[-1])\n",
    "    return torch.nn.functional.pad(tensors, pad_tuple, 'constant', pad_token_id)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _generate_one_step(prompts: dict):\n",
    "    idx = prompts['input_ids']  # (bs, prompt_length)\n",
    "    attention_mask = prompts['attention_mask']  # left-padded attention_mask\n",
    "    pixel_values = prompts[\"pixel_values\"]\n",
    "\n",
    "\n",
    "\n",
    "    # make sampling args can be overriden by inputs\n",
    "    do_sample = prompts.get('do_sample', DO_SAMPLE)\n",
    "\n",
    "\n",
    "    temperature = prompts.get('temperature', TEMP)\n",
    "\n",
    "    #generation_config = GenerationConfig(temperature=temperature, top_p=top_p, top_k=top_k)\n",
    "\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "        actions, response = actor_module.generate_action_verl(\n",
    "            input_ids=idx,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            padding_idx = processor.tokenizer.pad_token_id,\n",
    "            do_sample=do_sample,\n",
    "            unnorm_key=UNNORM_KEY,\n",
    "            temperature=temperature,)\n",
    "    \n",
    "    \n",
    "    assert processor.tokenizer.pad_token_id is not None\n",
    "\n",
    "    assert idx.ndim == 2\n",
    "    idx = pad_sequence_to_length(idx,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=processor.tokenizer.pad_token_id,left_pad=True)\n",
    "    \n",
    "    assert attention_mask.ndim == 2\n",
    "    attention_mask = pad_sequence_to_length(attention_mask,max_seq_len=MAX_PROMPT_LENGTH,pad_token_id=0,left_pad=True)\n",
    "    \n",
    "    \n",
    "    assert idx.device.type == 'cuda'\n",
    "    assert response.device.type == 'cuda'\n",
    "    #assert seq.device.type == 'cuda'\n",
    "    assert attention_mask.device.type == 'cuda'\n",
    "    assert pixel_values.device.type == 'cuda'\n",
    "    batch ={\n",
    "            'responses': response,\n",
    "            'input_ids': idx,\n",
    "            'attention_mask': attention_mask,\n",
    "            \"pixel_values\":pixel_values,\n",
    "            \"action\":actions,\n",
    "        }\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b35527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (__init__.py:7)\n",
      "WARNING:2025-10-13 12:26:15,735:No private macro file found!\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (__init__.py:8)\n",
      "WARNING:2025-10-13 12:26:15,736:It is recommended to use a private macro file\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /workspace/isaaclab/_isaac_sim/kit/python/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py (__init__.py:9)\n",
      "WARNING:2025-10-13 12:26:15,737:To setup, run: python /workspace/isaaclab/_isaac_sim/kit/python/lib/python3.11/site-packages/robosuite/scripts/setup_macros.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "from verl.envs.libero.libero_env import LiberoEnv\n",
    "batch_size = 16\n",
    "cfg_dict = {\n",
    "        \"task_suite_name\": \"libero_10\",\n",
    "        \"num_envs\": batch_size,\n",
    "        \"group_size\": batch_size,\n",
    "        \"num_group\": 1,\n",
    "        \"task_id\": 3,\n",
    "        \"seed\": 0,\n",
    "        \"use_fixed_reset_state_ids\": False,\n",
    "        \"ignore_terminations\": False,\n",
    "        \"auto_reset\": True,\n",
    "        \"max_episode_steps\": 512,\n",
    "        \"use_rel_reward\": False,\n",
    "        \"reward_coef\": 1.0,\n",
    "        \"only_eval\": False,\n",
    "        \"use_ordered_reset_state_ids\": False,\n",
    "        \"num_images_in_input\": 2,\n",
    "        \"init_params\": {\n",
    "            \"camera_depths\": False,\n",
    "            \"camera_heights\": 512,\n",
    "            \"camera_widths\": 512,\n",
    "            \"camera_names\": [\"agentview\", \"robot0_eye_in_hand\"],\n",
    "        },\n",
    "        \"controller_configs\": {\n",
    "            \"type\": \"OSC_POSE\",\n",
    "            \"input_max\": 1,\n",
    "            \"input_min\": -1,\n",
    "            \"output_max\": [0.05, 0.05, 0.05, 0.5, 0.5, 0.5],\n",
    "            \"output_min\": [-0.05, -0.05, -0.05, -0.5, -0.5, -0.5],\n",
    "            \"kp\": 150,\n",
    "            \"damping_ratio\": 1,\n",
    "            \"impedance_mode\": \"fixed\",\n",
    "            \"kp_limits\": [0, 300],\n",
    "            \"damping_ratio_limits\": [0, 10],\n",
    "            \"position_limits\": None,\n",
    "            \"orientation_limits\": None,\n",
    "            \"uncouple_pos_ori\": True,\n",
    "            \"control_delta\": True,\n",
    "            \"interpolation\": None,\n",
    "            \"ramp_ratio\": 0.2,\n",
    "        },\n",
    "        \"video_cfg\": {\n",
    "            \"save_video\": True,\n",
    "            \"video_base_dir\": \"/tmp/videos\",\n",
    "        },\n",
    "    }\n",
    "cfg = OmegaConf.create(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4cd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] using task orders [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "get task and trial id [ 50 100 150 200 250 300 350 400 450 500] [425 425 425 425 425 425 425 425] [8, 8, 8, 8, 8, 8, 8, 8] [25, 25, 25, 25, 25, 25, 25, 25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get task and trial id [ 50 100 150 200 250 300 350 400 450 500] [318 255 134 153  20  37   8  87] [6, 5, 2, 3, 0, 0, 0, 1] [18, 5, 34, 3, 20, 37, 8, 37]\n",
      "Initial data: {'images_and_states': {'full_image': tensor([[[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[110, 109, 105],\n",
      "          [111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          ...,\n",
      "          [110, 108, 105],\n",
      "          [111, 109, 106],\n",
      "          [110, 108, 104]],\n",
      "\n",
      "         [[111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          ...,\n",
      "          [111, 109, 106],\n",
      "          [110, 108, 105],\n",
      "          [109, 107, 104]],\n",
      "\n",
      "         [[110, 109, 105],\n",
      "          [110, 109, 105],\n",
      "          [110, 109, 105],\n",
      "          ...,\n",
      "          [102, 101,  99],\n",
      "          [101, 101,  99],\n",
      "          [101, 101,  98]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[139, 108,  67],\n",
      "          [138, 107,  67],\n",
      "          [138, 107,  66],\n",
      "          ...,\n",
      "          [117,  87,  50],\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50]],\n",
      "\n",
      "         [[139, 107,  66],\n",
      "          [139, 107,  66],\n",
      "          [138, 106,  65],\n",
      "          ...,\n",
      "          [118,  87,  51],\n",
      "          [118,  87,  51],\n",
      "          [117,  87,  50]],\n",
      "\n",
      "         [[138, 106,  65],\n",
      "          [138, 106,  64],\n",
      "          [138, 105,  64],\n",
      "          ...,\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [130, 130, 130],\n",
      "          [135, 135, 135],\n",
      "          [140, 140, 140]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [ 81,  81,  81],\n",
      "          [ 89,  89,  89],\n",
      "          [ 96,  96,  96]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [ 19,  19,  19],\n",
      "          [ 21,  21,  21],\n",
      "          [ 25,  25,  25]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[204, 187, 171],\n",
      "          [199, 182, 166],\n",
      "          [195, 178, 162],\n",
      "          ...,\n",
      "          [200, 183, 162],\n",
      "          [201, 184, 164],\n",
      "          [202, 185, 165]],\n",
      "\n",
      "         [[201, 184, 168],\n",
      "          [196, 180, 164],\n",
      "          [195, 178, 162],\n",
      "          ...,\n",
      "          [199, 182, 162],\n",
      "          [200, 183, 162],\n",
      "          [202, 185, 164]],\n",
      "\n",
      "         [[200, 183, 167],\n",
      "          [194, 177, 161],\n",
      "          [194, 177, 161],\n",
      "          ...,\n",
      "          [199, 181, 161],\n",
      "          [199, 182, 162],\n",
      "          [201, 184, 164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]]], dtype=torch.uint8), 'state': tensor([[-5.6177e-02, -4.7192e-03,  6.7928e-01,  3.1398e+00,  3.2948e-03,\n",
      "         -9.0280e-02,  2.0541e-02, -2.0544e-02],\n",
      "        [-3.0054e-01,  2.3009e-03,  1.1768e+00,  3.1403e+00, -1.2676e-03,\n",
      "         -8.7724e-02,  2.0543e-02, -2.0543e-02],\n",
      "        [-2.0961e-01,  5.6452e-03,  1.1744e+00,  3.1410e+00,  1.4104e-03,\n",
      "         -9.1271e-02,  2.0545e-02, -2.0541e-02],\n",
      "        [-2.0333e-01,  7.2501e-03,  1.1772e+00,  3.1407e+00,  2.6978e-03,\n",
      "         -8.6675e-02,  2.0543e-02, -2.0543e-02],\n",
      "        [-5.5079e-02,  1.4590e-02,  6.8229e-01,  3.1400e+00,  4.6525e-03,\n",
      "         -8.7061e-02,  2.0538e-02, -2.0544e-02],\n",
      "        [-6.1874e-02,  1.0370e-02,  6.7378e-01,  3.1409e+00,  2.2990e-03,\n",
      "         -9.1497e-02,  2.0544e-02, -2.0542e-02],\n",
      "        [-5.0013e-02, -1.1827e-03,  6.8789e-01,  3.1406e+00, -1.1507e-03,\n",
      "         -8.6317e-02,  2.0543e-02, -2.0543e-02],\n",
      "        [-5.1755e-02, -6.5780e-03,  6.7941e-01,  3.1395e+00,  3.8265e-03,\n",
      "         -8.6778e-02,  2.0539e-02, -2.0547e-02]])}, 'task_descriptions': ['put the white mug on the plate and put the chocolate pudding to the right of the plate', 'pick up the book and place it in the back compartment of the caddy', 'turn on the stove and put the moka pot on it', 'put the black bowl in the bottom drawer of the cabinet and close it', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the cream cheese box and the butter in the basket']}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import copy\n",
    "import torch.cuda.profiler as profiler\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "\n",
    "# batch_size = 32\n",
    "# batch_size = 8\n",
    "# max_steps = 200\n",
    "max_steps = 512\n",
    "# max_steps = 1024\n",
    "# max_steps = 256\n",
    "action_chunks_len = 8\n",
    "libero_env = LiberoEnv(cfg, rank=0, world_size=1)\n",
    "libero_env.is_start = True\n",
    "# The first call to step with actions=None will reset the environment\n",
    "obs_venv, _, terminated_venv, truncated_venv, info_venv = libero_env.step(actions=None)\n",
    "print(\"Initial data:\", obs_venv)\n",
    "# print(\"Initial data:\", init_data)\n",
    "# task_descriptions = [init_data['task_description']]\n",
    "# print(f\"Task description: {task_descriptions}\")\n",
    "\n",
    "# valid_video[init_data['task_file_name']].extend(init_data['valid_images'])\n",
    "# env_data = copy.deepcopy(init_data)\n",
    "# env_obs = env_data['obs']\n",
    "# for step in trange(max_steps // action_chunks_len):\n",
    "#     # print(\"Step:\", step)\n",
    "#     # prof.step()\n",
    "#     inputs = [_obs_to_input(env_obs)]\n",
    "#     vla_input = process_input(inputs, task_descriptions, config)\n",
    "#     # vla_input.update(meta_info)\n",
    "#     vla_output = _generate_one_step(vla_input)\n",
    "#     actions = vla_output[\"action\"]\n",
    "#     step_data = {\n",
    "#         \"responses\": vla_output[\"responses\"],\n",
    "#         \"input_ids\": vla_output[\"input_ids\"],\n",
    "#         \"attention_mask\": vla_output[\"attention_mask\"],\n",
    "#         \"pixel_values\": vla_output[\"pixel_values\"],\n",
    "#         \"action\": actions,\n",
    "#         \"step\": step\n",
    "#     }\n",
    "#     vla_history.append(step_data)\n",
    "    \n",
    "\n",
    "#     result = libero_env.step(actions[0])\n",
    "#     valid_video[init_data['task_file_name']].extend(result['valid_images'])\n",
    "#     env_obs = result[\"obs\"]\n",
    "\n",
    "#     step += action_chunks_len\n",
    "#     complete = result[\"complete\"]\n",
    "#     if complete:\n",
    "#         print(f\"Task completed at step {step}.\")\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b7fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07979179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task description: ['put the white mug on the plate and put the chocolate pudding to the right of the plate', 'pick up the book and place it in the back compartment of the caddy', 'turn on the stove and put the moka pot on it', 'put the black bowl in the bottom drawer of the cabinet and close it', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the cream cheese box and the butter in the basket']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [02:02<00:02,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get task and trial id [ 50 100 150 200 250 300 350 400 450 500] [406 324 456 251 303 485 364 316] [8, 6, 9, 5, 6, 9, 7, 6] [6, 24, 6, 1, 3, 35, 14, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [02:24<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 71:\n",
      "  Truncated: [[False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]\n",
      " [False False False False False False False  True]]\n",
      "  Info: {'final_observation': {'images_and_states': {'full_image': tensor([[[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[110, 109, 105],\n",
      "          [111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          ...,\n",
      "          [110, 108, 105],\n",
      "          [111, 109, 106],\n",
      "          [110, 108, 104]],\n",
      "\n",
      "         [[111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          [111, 109, 106],\n",
      "          ...,\n",
      "          [111, 109, 106],\n",
      "          [110, 108, 105],\n",
      "          [109, 107, 104]],\n",
      "\n",
      "         [[110, 109, 105],\n",
      "          [110, 109, 105],\n",
      "          [110, 109, 105],\n",
      "          ...,\n",
      "          [102, 101,  99],\n",
      "          [101, 101,  99],\n",
      "          [101, 101,  98]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[139, 108,  67],\n",
      "          [138, 107,  67],\n",
      "          [138, 107,  66],\n",
      "          ...,\n",
      "          [117,  87,  50],\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50]],\n",
      "\n",
      "         [[139, 107,  66],\n",
      "          [139, 107,  66],\n",
      "          [138, 106,  65],\n",
      "          ...,\n",
      "          [118,  87,  51],\n",
      "          [118,  87,  51],\n",
      "          [117,  87,  50]],\n",
      "\n",
      "         [[138, 106,  65],\n",
      "          [138, 106,  64],\n",
      "          [138, 105,  64],\n",
      "          ...,\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50],\n",
      "          [117,  86,  50]]],\n",
      "\n",
      "\n",
      "        [[[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [130, 130, 130],\n",
      "          [135, 135, 135],\n",
      "          [140, 140, 140]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [ 81,  81,  81],\n",
      "          [ 89,  89,  89],\n",
      "          [ 96,  96,  96]],\n",
      "\n",
      "         [[  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          [  0,   0,   0],\n",
      "          ...,\n",
      "          [ 19,  19,  19],\n",
      "          [ 21,  21,  21],\n",
      "          [ 25,  25,  25]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[204, 187, 171],\n",
      "          [199, 182, 166],\n",
      "          [195, 178, 162],\n",
      "          ...,\n",
      "          [200, 183, 162],\n",
      "          [201, 184, 164],\n",
      "          [202, 185, 165]],\n",
      "\n",
      "         [[201, 184, 168],\n",
      "          [196, 180, 164],\n",
      "          [195, 178, 162],\n",
      "          ...,\n",
      "          [199, 182, 162],\n",
      "          [200, 183, 162],\n",
      "          [202, 185, 164]],\n",
      "\n",
      "         [[200, 183, 167],\n",
      "          [194, 177, 161],\n",
      "          [194, 177, 161],\n",
      "          ...,\n",
      "          [199, 181, 161],\n",
      "          [199, 182, 162],\n",
      "          [201, 184, 164]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[208, 208, 208],\n",
      "          [198, 198, 198],\n",
      "          [192, 192, 192],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[193, 193, 193],\n",
      "          [192, 192, 192],\n",
      "          [187, 187, 187],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[194, 194, 194],\n",
      "          [192, 192, 192],\n",
      "          [187, 187, 187],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]],\n",
      "\n",
      "\n",
      "        [[[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 115, 112],\n",
      "          [117, 115, 111],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [117, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [116, 114, 110]],\n",
      "\n",
      "         [[ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          [ 13,  13,  13],\n",
      "          ...,\n",
      "          [118, 116, 112],\n",
      "          [116, 114, 110],\n",
      "          [117, 114, 111]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 79,  57,  45],\n",
      "          [ 76,  55,  44],\n",
      "          [ 73,  54,  44],\n",
      "          ...,\n",
      "          [ 83,  57,  45],\n",
      "          [ 84,  58,  46],\n",
      "          [ 85,  59,  47]],\n",
      "\n",
      "         [[ 77,  56,  46],\n",
      "          [ 76,  55,  46],\n",
      "          [ 74,  54,  45],\n",
      "          ...,\n",
      "          [ 82,  57,  44],\n",
      "          [ 82,  58,  45],\n",
      "          [ 83,  58,  46]],\n",
      "\n",
      "         [[ 77,  56,  47],\n",
      "          [ 76,  55,  47],\n",
      "          [ 76,  55,  47],\n",
      "          ...,\n",
      "          [ 80,  57,  44],\n",
      "          [ 81,  57,  44],\n",
      "          [ 81,  58,  45]]]], dtype=torch.uint8), 'state': tensor([[ 2.0372e-01,  1.8076e-03,  5.0458e-01,  2.4430e+00, -1.7175e+00,\n",
      "         -1.7897e-01,  2.8406e-02, -9.6868e-03],\n",
      "        [-3.5024e-01, -1.3770e-01,  1.0390e+00,  2.3047e+00, -1.9535e+00,\n",
      "          3.0461e-01,  1.8286e-02, -1.8228e-02],\n",
      "        [ 1.3750e-02,  3.9904e-02,  9.9208e-01,  1.0545e+00,  2.7934e+00,\n",
      "          6.2454e-01,  3.8114e-02, -3.9445e-02],\n",
      "        [-1.2987e-01,  2.6229e-02,  9.7806e-01,  2.6432e+00, -2.1324e+00,\n",
      "         -1.0735e+00,  3.9984e-02, -3.9958e-02],\n",
      "        [ 1.3578e-01, -1.7504e-01,  5.3056e-01,  2.6169e+00,  1.4230e+00,\n",
      "         -4.4132e-02,  3.8669e-02, -3.8921e-02],\n",
      "        [-1.5925e-02,  2.4835e-02,  5.4107e-01,  2.9887e+00, -8.5354e-01,\n",
      "         -1.0889e-01,  3.4206e-02, -3.6728e-02],\n",
      "        [-2.1667e-02,  2.3402e-01,  6.0030e-01,  3.0994e+00, -3.0624e-01,\n",
      "         -2.8331e-02,  3.2884e-02, -3.0342e-02],\n",
      "        [ 7.8780e-02,  6.5625e-02,  4.7441e-01,  3.1785e+00,  7.0774e-02,\n",
      "         -2.5154e-01,  3.8852e-02, -3.9250e-02]])}, 'task_descriptions': ['put the white mug on the plate and put the chocolate pudding to the right of the plate', 'pick up the book and place it in the back compartment of the caddy', 'turn on the stove and put the moka pot on it', 'put the black bowl in the bottom drawer of the cabinet and close it', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the alphabet soup and the tomato sauce in the basket', 'put both the cream cheese box and the butter in the basket']}, 'final_info': {'env_id': [0, 1, 2, 3, 4, 5, 6, 7], 'episode': {'success_once': tensor([False, False, False, False, False, False, False, False]), 'return': tensor([0., 0., 0., 0., 0., 0., 0., 0.]), 'episode_len': tensor([512, 512, 512, 512, 512, 512, 512, 512], dtype=torch.int32), 'reward': tensor([0., 0., 0., 0., 0., 0., 0., 0.])}}, '_final_info': array([ True,  True,  True,  True,  True,  True,  True,  True]), '_final_observation': array([ True,  True,  True,  True,  True,  True,  True,  True]), '_elapsed_steps': array([ True,  True,  True,  True,  True,  True,  True,  True])}\n",
      "  success rate: 0 / 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from verl.envs.libero.utils import normalize_gripper_action, invert_gripper_action\n",
    "task_descriptions = obs_venv['task_descriptions']\n",
    "print(f\"Task description: {task_descriptions}\")\n",
    "config = {\n",
    "    \"center_crop\": True,\n",
    "    \"num_steps_wait\": 10\n",
    "}\n",
    "vla_history = []\n",
    "for step in trange(max_steps // action_chunks_len):\n",
    "\n",
    "    # print(\"Step:\", step)\n",
    "    # prof.step()\n",
    "    vla_input = process_input(obs_venv, config)\n",
    "    # vla_input.update(meta_info)\n",
    "    vla_output = _generate_one_step(vla_input)\n",
    "    actions = vla_output[\"action\"]\n",
    "    # if step < 1:\n",
    "    #     actions = torch.tensor([[0, 0, 0, 0, 0, 0, 1]]).repeat(batch_size, action_chunks_len, 1).numpy()\n",
    "    #     print(actions.shape)    \n",
    "    step_data = {\n",
    "        \"responses\": vla_output[\"responses\"],\n",
    "        \"input_ids\": vla_output[\"input_ids\"],\n",
    "        \"attention_mask\": vla_output[\"attention_mask\"],\n",
    "        \"pixel_values\": vla_output[\"pixel_values\"],\n",
    "        \"action\": actions,\n",
    "        \"step\": step\n",
    "    }\n",
    "    vla_history.append(step_data)\n",
    "\n",
    "    # TODO(caiyunke.astra): check if need to invert the gripper action\n",
    "    # Invert the gripper action\n",
    "    normalized_action = normalize_gripper_action(actions, binarize=True)\n",
    "    inverted_action = invert_gripper_action(normalized_action)\n",
    "\n",
    "    # actions[..., -1] = actions[..., -1] *  -1.0\n",
    "    \n",
    "\n",
    "    # result = libero_env.step(actions[0])\n",
    "    # result = libero_env.chunk_step(actions)\n",
    "    result = libero_env.chunk_step(inverted_action)\n",
    "    obs_venv, _, terminated_venv, truncated_venv, info_venv = result\n",
    "    step += action_chunks_len\n",
    "    if terminated_venv.any() or truncated_venv.any():\n",
    "        print(f\"Step {step}:\")\n",
    "        if terminated_venv.any():\n",
    "            print(f\"  Terminated: {terminated_venv.cpu().numpy()}\")\n",
    "        if truncated_venv.any():\n",
    "            print(f\"  Truncated: {truncated_venv.cpu().numpy()}\")\n",
    "        if info_venv:\n",
    "            print(f\"  Info: {info_venv}\")\n",
    "    # if complete:\n",
    "    #     print(f\"Task completed at step {step}.\")\n",
    "    #     break\n",
    "success_count = info_venv[\"final_info\"][\"episode\"][\"success_once\"].int().sum().item()\n",
    "print(f\"  success rate: {success_count} / {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7b8483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "libero_env.flush_video(video_sub_dir=f\"episode_{7}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b97f58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "libero_env.env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
